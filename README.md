# MATES Project Overview

## Project Scope

Strong software engineering practices are essential for ensuring the reliability and scalability of modern data science and machine learning projects. This project aims at providing hands-on experience in software engineering and good software practices, specifically regarding ML projects.

To put this into practice, our team has chosen to fine-tune an existing model in the task of dog breed classification. For this, the MobileNetV2 model was used as a based model.

This project will not only strengthen our technical proficiency in model fine-tuning and machine learning workflows but will also provide valuable experience in applying high-quality standard software engineering practices. By integrating principles such as version control, continuous integration, and code modularity, we aim to deliver a scalable and maintainable solution.

This project is focused on **dog breed classification** using image data. The dataset consists of labeled dog breed images, which have been preprocessed to train a fine-tuned **MobileNetV2** model. The project emphasizes **best practices in software engineering**, including the use of version control, modular code, and machine learning experiment tracking, to create a scalable, maintainable machine learning pipeline.

## Project Structure

The folder structure follows a well-organized layout, ensuring smooth navigation and modularity for various components, such as data processing, model training, deployment, and more. Below is a detailed structure of the project directories and files:

```
./
├── Makefile                       <- Automation commands for tasks like data processing and training
├── README.md                      <- Main project documentation (this file)
├── data/
│   ├── README.md                  <- Documentation of the data processing pipeline
│   ├── dog_catalogue_data.json    <- Dog breed catalog data in JSON format
│   ├── output/                    <- Final model predictions
│   │   └── predictions_test.csv   <- Test predictions generated by the model
│   ├── processed/                 <- Processed data used for model training
│   │   ├── X_train.pkl            <- Training features
│   │   ├── X_valid.pkl            <- Validation features
│   │   ├── output_shape.pkl       <- Shape information of output labels
│   │   ├── y_train.pkl            <- Training labels
│   │   └── y_valid.pkl            <- Validation labels
│   └── raw/                       <- Raw dataset files
│       ├── labels.csv             <- Image labels for training data
│       ├── test/                  <- Test images (JPG files)
│       ├── test.dvc               <- DVC tracking for the test dataset
│       ├── train/                 <- Training images (JPG files)
│       └── train.dvc              <- DVC tracking for the training dataset
│
├── docs/                          <- Documentation for the project
│   ├── Dataset_card.md            <- Description of the dataset used
│   ├── Model_card.md              <- Model details and performance
│   └── README.md
│
├── dvc.lock                       <- DVC pipeline stage lock file
├── dvc.yaml                       <- DVC configuration for the data pipeline
├── linter.txt                     <- Linter output logs
├── ls.txt                         <- Logs from system directory listing
├── mates/                         <- Main source code for the project
│   ├── README.md
│   ├── __init__.py                <- Marks the `mates` directory as a Python package
│   ├── app/                       <- Code for the API to serve the model
│   │   └── api.py
│   ├── config.py                  <- Configuration settings
│   ├── features/                  <- Feature extraction and transformation logic
│   │   ├── __init__.py
│   │   ├── deepchecks.py          <- Automated dataset validation using DeepChecks
│   │   ├── features.py            <- Custom feature engineering functions
│   │   ├── gaissa/                <- GAiSSA plugin for tracking sustainability metrics
│   │   │   ├── __init__.py
│   │   │   ├── calculator.py
│   │   │   ├── gaissaplugin.py
│   │   │   ├── main_script.py
│   │   │   └── plugin_interface.py
│   │   └── utils.py               <- Utility functions for feature processing
│   ├── modeling/                  <- Code for model training and prediction
│   │   ├── __init__.py
│   │   ├── predict.py             <- Inference scripts for generating predictions
│   │   ├── prepare.py             <- Data preparation scripts for model input
│   │   └── train.py               <- Training scripts for model fine-tuning
│   └── streamlit.py               <- Streamlit app for model visualization
│
├── metrics/                       <- Metrics for model evaluation and environmental impact
│   ├── README.md
│   ├── gaissa/                    <- GAiSSA sustainability tracking
│   │   ├── gaissa_log.txt
│   │   └── gaissa_mobilenet_exp_batch_62.csv
│   ├── mobilenet_exp_batch_32_emissions.csv
│   ├── mobilenet_exp_batch_62_emissions.csv
│
├── models/                        <- Serialized trained models
│   ├── README.md
│   ├── mobilenet_exp_batch_32.h5  <- Model trained on batch 32
│   └── mobilenet_exp_batch_62.h5  <- Model trained on batch 62
│
├── notebooks/                     <- Jupyter notebooks for exploratory data analysis
│   ├── 01_dataset_exploration.ipynb
│   └── README.md
│
├── params.yaml                    <- Hyperparameters and configuration for training
├── poetry.lock                    <- Poetry dependency lock file
├── pyproject.toml                 <- Python project configuration and dependencies
├── reports/                       <- Generated reports and visualizations
│   ├── README.md
│   ├── deepchecks/                <- DeepChecks validation reports
│   │   └── train_val_split_check.html
│   └── figures/                   <- Figures for report generation and model comparison
│       ├── Competition_models.png
│       ├── Competition_results.png
│       ├── example_image.jpg
│       ├── imbalanced_dataset.png
│       └── streamlit/
│           ├── <...>.jpg
│           └── footer.jpg
│
├── setup.cfg                      <- Configuration for code style and linting tools
└── tests/                         <- Unit tests for validating code functionality

21 directories, 20676 files
```

---

## Key Project Components

### 1. **Data Pipeline**
- **Raw Data**: The `data/raw/` folder contains the raw training and test images, as well as the label file. Data versioning is managed through **DVC** (Data Version Control).
- **Processed Data**: Processed files in the `data/processed/` folder are used as input for the model training pipeline. These files include the train-validation split data stored as `.pkl` files.
- **Outputs**: The final predictions generated by the model on the test set are saved in the `data/output/` folder.

### 2. **Modeling**
- **Training**: The `mates/modeling/train.py` script fine-tunes the **MobileNetV2** model for dog breed classification. The training process uses preprocessed data and generates models stored in the `models/` folder.
- **Inference**: After training, model inference is performed using `mates/modeling/predict.py`, allowing predictions on new images.
- **API**: The trained model is served through an API built in `mates/app/api.py`, enabling external interactions for real-time predictions.

### 3. **Metrics and Sustainability**
- **Model Performance**: Metrics such as accuracy, precision, recall, and F1-score are stored in the `metrics/` folder, enabling comprehensive evaluation of model performance.
- **GAiSSA Sustainability**: The project tracks the environmental impact of model training, with emissions data logged by **GAiSSA** under `metrics/gaissa/`.

### 4. **Streamlit Web App**
A **Streamlit** web app (`mates/streamlit.py`) allows users to interactively test the model by uploading images and receiving predictions in real-time. Visualizations are available in the `reports/figures/` folder to compare different models and test results.

### 5. **Testing and Linting**
- **Unit Tests**: The `tests/` directory contains unit tests to ensure code correctness and reliability. Tests cover various aspects, from data preprocessing to model predictions.
- **Code Quality**: The project enforces consistent coding practices using **Black** and **flake8**, configured in `setup.cfg`.

---

## Getting Started

1. **Clone the Repository**:
   ```bash
   git clone <repository-url>
   cd <repository-folder>
   ```

2. **Set Up Environment**:
   - Use **Poetry** to install dependencies:
     ```bash
     poetry install
     ```

3. **Data Processing**:
   - Fetch the dataset and prepare it using **DVC**:
     ```bash
     dvc pull
     ```

4. **Model Training**:
   - Run the training script to fine-tune the MobileNetV2 model:
     ```bash
     python mates/modeling/train.py

---

## Project Description

Strong software engineering practices are essential for ensuring the reliability and scalability of modern data science and machine learning projects. This project aims at providing hands-on experience in software engineering and good software practices, specifically regarding ML projects.

To put this into practice, our team has chosen to fine-tune an existing model in the task of dog breed classification. For this, the MobileNetV2 model was used as a based model.

This project will not only strengthen our technical proficiency in model fine-tuning and machine learning workflows but will also provide valuable experience in applying high-quality standard software engineering practices. By integrating principles such as version control, continuous integration, and code modularity, we aim to deliver a scalable and maintainable solution.

---

## Contact
For any questions or issues regarding this dataset, please contact:

- [Noa Mediavilla](mailto:noa.mediavilla@estudiantat.upc.edu)
- [Andrea Tomás](mailto:andrea.tomas@estudiantat.upc.edu)
- [Maria Tubellas](mailto:maria.tubella@estudiantat.upc.edu)
- [Matilde Simoes](mailto:matilde.simoes@estudiantat.upc.edu)
- [JP. Zaldivar](mailto:juan.pablo.zaldivar@estudiantat.upc.edu)