# MATES Project Overview

## Project Scope

Strong software engineering practices are essential for ensuring the reliability and scalability of modern data science and machine learning projects. This project aims at providing hands-on experience in software engineering and good software practices, specifically regarding ML projects.

To put this into practice, our team has chosen to fine-tune an existing model in the task of dog breed classification. For this, the MobileNetV2 model was used as a based model.

This project will not only strengthen our technical proficiency in model fine-tuning and machine learning workflows but will also provide valuable experience in applying high-quality standard software engineering practices. By integrating principles such as version control, continuous integration, and code modularity, we aim to deliver a scalable and maintainable solution.

This project is focused on **dog breed classification** using image data. The dataset consists of labeled dog breed images, which have been preprocessed to train a fine-tuned **MobileNetV2** model. The project emphasizes **best practices in software engineering**, including the use of version control, modular code, and machine learning experiment tracking, to create a scalable, maintainable machine learning pipeline.

## Project Structure

The folder structure follows a well-organized layout, ensuring smooth navigation and modularity for various components, such as data processing, model training, deployment, and more. Below is a detailed structure of the project directories and files:

```
./
├── Makefile                       <- Automation commands for tasks like data processing and training
├── README.md                      <- Main project documentation (this file)
├── data/
│   ├── README.md                  <- Documentation of the data processing pipeline
│   ├── dog_catalogue_data.json    <- Dog breed catalog data in JSON format
│   ├── output/                    <- Final model predictions
│   │   └── predictions_test.csv   <- Test predictions generated by the model
│   ├── processed/                 <- Processed data used for model training
│   │   ├── X_train.pkl            <- Training features
│   │   ├── X_valid.pkl            <- Validation features
│   │   ├── output_shape.pkl       <- Shape information of output labels
│   │   ├── y_train.pkl            <- Training labels
│   │   └── y_valid.pkl            <- Validation labels
│   └── raw/                       <- Raw dataset files
│       ├── labels.csv             <- Image labels for training data
│       ├── test/                  <- Test images (JPG files)
│       ├── test.dvc               <- DVC tracking for the test dataset
│       ├── train/                 <- Training images (JPG files)
│       └── train.dvc              <- DVC tracking for the training dataset
│
├── docs/                          <- Documentation for the project
│   ├── Dataset_card.md            <- Description of the dataset used
│   ├── Model_card.md              <- Model details and performance
│   └── README.md
│
├── dvc.lock                       <- DVC pipeline stage lock file
├── dvc.yaml                       <- DVC configuration for the data pipeline
├── linter.txt                     <- Linter output logs
├── ls.txt                         <- Logs from system directory listing
├── mates/                         <- Main source code for the project
│   ├── README.md
│   ├── __init__.py                <- Marks the `mates` directory as a Python package
│   ├── app/                       <- Code for the API to serve the model
│   │   └── api.py
│   ├── config.py                  <- Configuration settings
│   ├── features/                  <- Feature extraction and transformation logic
│   │   ├── __init__.py
│   │   ├── deepchecks.py          <- Automated dataset validation using DeepChecks
│   │   ├── features.py            <- Custom feature engineering functions
│   │   ├── gaissa/                <- GAiSSA plugin for tracking sustainability metrics
│   │   │   ├── __init__.py
│   │   │   ├── calculator.py
│   │   │   ├── gaissaplugin.py
│   │   │   ├── main_script.py
│   │   │   └── plugin_interface.py
│   │   └── utils.py               <- Utility functions for feature processing
│   ├── modeling/                  <- Code for model training and prediction
│   │   ├── __init__.py
│   │   ├── predict.py             <- Inference scripts for generating predictions
│   │   ├── prepare.py             <- Data preparation scripts for model input
│   │   └── train.py               <- Training scripts for model fine-tuning
│   └── streamlit.py               <- Streamlit app for model visualization
│
├── metrics/                       <- Metrics for model evaluation and environmental impact
│   ├── README.md
│   ├── gaissa/                    <- GAiSSA sustainability tracking
│   │   ├── gaissa_log.txt
│   │   └── gaissa_mobilenet_exp_batch_62.csv
│   ├── mobilenet_exp_batch_32_emissions.csv
│   ├── mobilenet_exp_batch_62_emissions.csv
│
├── models/                        <- Serialized trained models
│   ├── README.md
│   ├── mobilenet_exp_batch_32.h5  <- Model trained on batch 32
│   └── mobilenet_exp_batch_62.h5  <- Model trained on batch 62
│
├── notebooks/                     <- Jupyter notebooks for exploratory data analysis
│   ├── 01_dataset_exploration.ipynb
│   └── README.md
│
├── params.yaml                    <- Hyperparameters and configuration for training
├── poetry.lock                    <- Poetry dependency lock file
├── pyproject.toml                 <- Python project configuration and dependencies
├── reports/                       <- Generated reports and visualizations
│   ├── README.md
│   ├── deepchecks/                <- DeepChecks validation reports
│   │   └── train_val_split_check.html
│   └── figures/                   <- Figures for report generation and model comparison
│       ├── Competition_models.png
│       ├── Competition_results.png
│       ├── example_image.jpg
│       ├── imbalanced_dataset.png
│       └── streamlit/
│           ├── <...>.jpg
│           └── footer.jpg
│
├── setup.cfg                      <- Configuration for code style and linting tools
└── tests/                         <- Unit tests for validating code functionality

21 directories, 20676 files
```

---

## Key Project Components

### 1. **Data Pipeline**
- **Raw Data**: The `data/raw/` folder contains the raw training and test images, as well as the label file. Data versioning is managed through **DVC** (Data Version Control).
- **Processed Data**: Processed files in the `data/processed/` folder are used as input for the model training pipeline. These files include the train-validation split data stored as `.pkl` files.
- **Outputs**: The final predictions generated by the model on the test set are saved in the `data/output/` folder.

### 2. **Modeling**
- **Training**: The `mates/modeling/train.py` script fine-tunes the **MobileNetV2** model for dog breed classification. The training process uses preprocessed data and generates models stored in the `models/` folder.
- **Inference**: After training, model inference is performed using `mates/modeling/predict.py`, allowing predictions on new images.
- **API**: The trained model is served through an API built in `mates/app/api.py`, enabling external interactions for real-time predictions.

### 3. **Metrics and Sustainability**
- **Model Performance**: Metrics such as accuracy, precision, recall, and F1-score are stored in the `metrics/` folder, enabling comprehensive evaluation of model performance.
- **GAiSSA Sustainability**: The project tracks the environmental impact of model training, with emissions data logged by **GAiSSA** under `metrics/gaissa/`.

### 4. **Streamlit Web App**
A **Streamlit** web app (`mates/streamlit.py`) allows users to interactively test the model by uploading images and receiving predictions in real-time. Visualizations are available in the `reports/figures/` folder to compare different models and test results.

### 5. **Testing and Linting**
- **Unit Tests**: The `tests/` directory contains unit tests to ensure code correctness and reliability. Tests cover various aspects, from data preprocessing to model predictions.
- **Code Quality**: The project enforces consistent coding practices using **Black** and **flake8**, configured in `setup.cfg`.

---

## Getting Started

Follow these steps to set up the project on your local machine and get it running.

### 1. Clone the Repository
Begin by cloning the repository to your local machine. This will create a copy of the project files on your system.
```bash
git clone <repository-url>
cd <repository-folder>
```
**Note**: Replace `<repository-url>` with the actual URL of the repository and `<repository-folder>` with the name of the folder created after cloning.

### 2. Set Up Environment
To manage dependencies efficiently, we use **Poetry**. Follow these steps:

- **Install Dependencies**:
  Ensure you have Python 3.11 installed. Use Poetry to install all required dependencies specified in the `pyproject.toml` file:
  ```bash
  python3.11 -m poetry install
  ```

- **Activate the Virtual Environment**:
  Activate the Poetry-managed virtual environment to ensure all commands run within the context of this environment:
  ```bash
  python3.11 -m poetry shell
  ```

### 3. Data Processing
The project relies on a specific dataset. Use **DVC** (Data Version Control) to pull the necessary data files:
```bash
dvc pull
```
**Explanation**: This command fetches the dataset stored in DVC's remote storage, ensuring you have the correct version of the data for your model training.

### 4. Model Training
Once your environment is set up and the data is ready, you can start training your model. To fine-tune the MobileNetV2 model, execute the following command. You may also modify hyperparameters in the `params.yaml` file to customize the training process:
```bash
dvc repro
```
**Tip**: Review the `params.yaml` file before running this command to adjust settings such as batch size, or number of epochs as needed.

### 5. Model Inference
After training, you can evaluate the model using new images. The project provides a web interface and API for this purpose:

- **Run the Streamlit Web Interface**:
  Launch the Streamlit application, which provides an interactive UI to test your model:
  ```bash
  streamlit run mates/streamlit.py
  ```

- **Run the API in Local Mode**:
  If you prefer to interact with the model via an API, run the FastAPI server locally:
  ```bash
  uvicorn mates.app.api:app --host 0.0.0.0 --port 5000 --reload
  ```

- **Run the API in a Virtual Machine**:
  If you're operating in a virtual machine environment, use this command:
  ```bash
  uvicorn mates.app.api:app --host 0.0.0.0 --port 8080 --reload
  ```

### Configuring API URLs
Depending on whether you are running the API locally or in a virtual machine, you'll need to update the API URL in the `streamlit.py` file:

```python
# Set the appropriate API URL
API_URL = "http://localhost:5000/"  # For local FastAPI server
API_URL = "http://nattech.fib.upc.edu:40390/"  # For VM FastAPI server
```

**Important**: Ensure that the API URL matches the mode you are using to avoid connectivity issues.

---


## Contact
For any questions or issues regarding this dataset, please contact:

- [Noa Mediavilla](mailto:noa.mediavilla@estudiantat.upc.edu)
- [Andrea Tomás](mailto:andrea.tomas@estudiantat.upc.edu)
- [Maria Tubella](mailto:maria.tubella@estudiantat.upc.edu)
- [Matilde Simoes](mailto:matilde.simoes@estudiantat.upc.edu)
- [JP. Zaldivar](mailto:juan.pablo.zaldivar@estudiantat.upc.edu)
